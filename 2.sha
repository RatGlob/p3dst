//Cg

/*
First we try to understand what this vertex shaders and fragment shaders are
for. The vertex shader handles vertices, while the fragment shader processes
fragments. In DirectX they are called vertex shader and pixel shader. There is a
reason why fragment shader is a better name, but for the moment think of a
fragment as a pixel.

The vshader function below is called once for every processed vertex, while the
fshader is once called for every drawn pixel. Because our cube has 24 vertices
vshader is called 24 times per cube in this example. fshader is called for every
visible pixel of this cube. The larger the cube on the screen the more often
fshader needs to be called so we can not say it is called 100 times or 1000
times per cube. If you the cube is far away, so we only see one pixel on the
screen, then the vshader is still called 24 times, while the fshader may only be
called once. The order is always the same first vshader then fshader. Maybe you
remember the fact that if a vertex is processed this vertex does not know
anything about any other vertices. The GPU can therefore run the vshader
multiple times at the same time. You write this function only once, but it is
called in parallel as often as the GPU can handle. The same is true for the
vshader. A extremely powerful GPU can call fshader for each individual pixel at
the same time. Maybe you can see that there are some problems. If I have cube
that fills my whole 800 x 600 screen, a perfect GPU has 480000 separate
processors. At least today this is impossible. Each of this small processors
have to process more than one pixel, problem is here if our shaders are not to
easy (that may happen faster than you think) the GPU may need to much time to
process all vertices or pixels and therefore your FPS start to drop. Today
shaders can be quite complex but one single shader can not have thousands of
lines. Often you need to write tons of specialized shaders which you apply to
your scene. The Auto Shader of Panda3D is an example of this. It may be possible
that each node has another shader. You do not see this because they are
generated on the fly.

Before you read on, maybe modify the sample 0.py and add a CartoonInk
post process filter to your scene. setCartoonInk is method of the class
CommonFilters. Post processing means, that after your image is rendered and
normally finished to display, you start to modify the pixels. More precisely: You
modify ALL pixels visible on the screen. At least on my computer the FPS varies
greatly if I have a small window or if I have a large window. A post process
vertex shader only needs to process 4 vertices (the corners of the window) but
millions of pixels, therefore this is an example where only the fragment shader
is limiting the performance of your application (if you are not crazy and write
your SETI client into the vertex shader).
*/

/*
First some basic facts after you skimmed the vshader function. As already
written the vshader function handles each vertex. The only thing a vertex shader
can is calculating properties for vertices. One of such a property is the
position. Therefore one thing, and maybe to most obvious property is the
position. A vertex shader can move around vertices. In this sample we only do
move around the vertices, but in the next sample we will calculate some more
properties for a single vertex. A vertex shader can not create new vertices, nor
can it delete vertices.

If we look a bit closer to this vertex shader we can see a new line with the
keyword "uniform" and the with the "in" keyword. The "in" keyword means that
there is some input from somewhere, the input here is named vtx_position. We
have to look once more to the "List of Possible Shader Inputs", and see that
vtx_positions is reserved name. So whats is the input here? Exactly the 24
vertex coordinates that are specified in the egg file. Because we have 3 cubes,
they are sent three times through this shader. With exactly I mean exactly. But
this exactly is a problem. If this shader gets three times the same vertices why
can you see then 3 cubes side by side? The answer is, we have to do this
ourself. This whole shader is in fact only here to solve this question. We will
in one minute try to answer how this is done, but for moment, we only try to
understand what all this keywords means. At least I hope, that you understand
that we need only get the raw vtx_position as input from Panda3D.

Next what means this "uniform". "uniform" is like the keyword "in", but an
uniform is the same for every call to vshader. While vtx_position changes on
every of the 24 calls to vshader, vtx_position never changes. You can pass an
uniform to the vhader or to the fshader, but not every uniform is usefull in
both. We will see later that Panda3D has to modify the mat_modelproj for every
cube.

The type float4x4 is fixed size array type with 4 * 4 floats or in other words
16 floats. If we like we can store 16 independent floats in a float4x4 variable,
but most often we store a matrix in a float4x4 (This sentence is a bit
misleading, because a 4x4float is in fact a matrix).

Now one of the toughest thing. If you never read something about a matrix and a
matrix multiplication I guess it is not that easy to understand.

If you look up mat_modelproj in "List of Possible Shader Inputs" you see the
description Composed Modelview/Projection Matrix. We roll up the problem from
behind. If we sum up everything that was written about this shader: We have 2
inputs, once a scary matrix we do not understand and second the raw vertex
positions from the cube. We create an output based on this 2 inputs, and as
result we can see 3 perspectively correct cubes. With perspective I man that the
more far away the cube, the smaller it is. If you look closer you can see that
the face of a cube that is nearer to you is larger than a the face that is farer
away (You can not see this face but you could imagine where it should be). Then
there is this mul function that only multiplies a matrix with a vector
respectively a float4x4 with a float4. What do we conclude from this facts? This
mat_modelproj must contain something that is responsible that the cubes are side
by side and this mat_modelproj must contain something that make your cubes look
perspectively correct. Maybe you thought the GPU cares about this perspective
thing but this is not true (and that is good thing, because it gives us the
possibility to do calculates that are no perspectively correct).

mat_modelproj is composite from a so called modelview matrix, and from a so
called projection matrix. There is a second vertex shader in this sample that is
a bit more complex but does the same thing. You just can see there this
composition of the two matrices.

Ok therefore we need to understand what this modelview matrix is first. I repeat
myself maybe to often, but remember that this lazy dumb GPU (a bit too wicked,
the NVIDIA/ATI engineers are damn smart people) only gives us the raw vertices
from the egg file (Ok there is Panda3D in between that cares about this tedious
task). The first thing we have to do is to move each cube to his position. So
you may ask why do we don't feed the vshader with the cubes position (not the
vertex positions this the time)? The answer is, yes we can do this on your own,
if we really like it (After you read the tutorials 0.py up to 5.py you should be
able to do this on your own). Why then this complicated modelview matrix, if
there is a simpler solution? I add following requirements. I like to rotate the
cube, I like to scale the cube and I like to shear the cube. You can do this all
on your own and add tons of uniforms to your shader. But one clever guy long
time ago had the brilliant idea to store all this information in a 4x4 matrix.
Think of a 4x4 matrix as pool that stores positions, rotations, shears and
translations, and maybe some fancy things no one can imagine. But do not think
of it as a divine thing, you can not do everything this are only 16 floats. The
Python sample that loads this shader has some lines, which if disabled, can show
you the modelview matrix of every node. If you read this matrices carefully you
see that only one number differs for each of the 3 cubes. If you are brave try
to use setScale (only with one parameter, not three) in Python on one of your
cubes and look at the matrices and the output onto your screen. The braver ones
start to setShear and the bravest ones start to use setHpr (start with multiples
of 90 degree) or use setMat directly on a cubes NodePath.

As you maybe see I do not try do explain how matrices really work, I hope you
start to play around with. I always do it like this first, if you then think,
wow they rock, go to the library and get a book. I know that is the
unprofessional way to learn things, but I am not a genius. Forgive me my
talkativeness ;)

To summarize once more with technical terms: This modelview matrix transforms
all vertices from the model space to view space. Once more: We move every vertex
to their absolute correct location in the Panda3D world. There are no more
relative coordinates like they were before. Nor OpenGL neither DirectX know the
concept of a camera. That means if we move our virtual camera to the left we
have to move our cubes to the right. We are cheating, that rights. If a player
runs around in a world, we do not move the player, we move the world. Panda3D
does well in hiding this fact, nevertheless it is the truth. Maybe now you
understand the term modelview better. Model space is the space where the models
lives in. View space is the space where the viewer lives.

To calculate the mat_modelproj we need one more matrix, the projection matrix.
Maybe you remember the call to setFov in the Python code. The belongs to the
camera as well, but as said there is no camera at all, so we even have to do
this by ourself. with call to setFov Panda3D generates internally a correct
projection matrix. This projection matrix is a bit harder to understand, because
if you look at the matrix it is not obvious what happens. The method
getProjectionMat of the class PerspectiveLens or the same method of the
OrthographicLens class may help. If your application uses PerspectiveLens (this
examples does e.g. because that is the default) just have to remember that
anyone has to care that a face that is farther away has to be smaller than a
face that is nearer to the viewer. This information is stored in the projection
matrix.

Now we have both this matrices. One cool thing about matrices is the following
possibility. You can apply the modelview matrix to every vertex and then apply
the projection matrix to every vertex. Or you can first multiply the projection
matrix with the modelview matrix (but care about the order). What is the
difference? The more vertices you have the faster is the second method, because
we have to do less multiplications.

Hope I never have to write that much about one single line :)
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
}

/*
DIRTY
We have an alternative vertex shader that does the exactly same thing as his
predecessor, but this time we create the mat_modelproj on our own.
*/
// void vshader(
//    uniform float4x4 mat_modelview,
//    uniform float4x4 mat_projection,
//    in float4 vtx_position : POSITION,
//    out float4 l_position : POSITION)
//{
//    float4x4 my_mat_modelproj = mul(mat_projection, mat_modelview);
//    l_position = mul(my_mat_modelproj, vtx_position);
//}

/*
Our fshader is called for every pixel that needs to be drawn into the color
buffer. We then calculate a color and assign it to the o_color variable. The GPU
then creates a color based on the chosen color depth, and then overwrites the
color buffer with this new information. The word overwriting is carefully
chosen here. It may be possible, that in your scene all 3 cubes are not next to
each other, but in front of each other. There are 2 possible scenarios. First
the rearmost cube is drawn, and at last the foremost cube is drawn. In this case
it is possible that one pixel need to be overdrawn up to 3 times. The second
scenario is that first the foremost cube is drawn and at last the rearmost cube.
In this case the the depth buffer of you GPU discards all pixels of the cubes
behind the first one, so the fshader needs not be called for this discarded
pixels. There is third scenario where you have alpha transparency, in this case
you have to fully draw all the cubes, independent of their order.
*/
void fshader(
    out float4 o_color : COLOR)
{
    /*
    DIRTY
    The fragment shader is as simple as the previous fragment shader. Because
    there is still no input we can not do cool things here, but at least we can
    see a color, because the vertex shader now works. One more thing that is
    typical of shader, the shader itself does not know which pixel it is
    drawing. If you need this information you have to generated it yourself
    (which we are not able to do know).
    */
    o_color = float4(1.0, 0.0, 1.0, 1.0);
    //o_color = float4(1.0, 0.0, 0.0, 1.0);
    //o_color = float4(1.0, 0.0, 0.0, 0.0);

    /*
    DIRTY
    Here we calculate more constant colors, but this time with the help of a
    function. Cg include some function that help to do basic math that is often
    used in 3D graphic applications. Most of this function you can write in Cg
    yourself, but they are often then slower. Try as often as possible to use
    included functions. lerp is an example of such an included function. It
    linearly interpolates to two first parameters. The third parameters says how
    near or far away you like a value to be calculated by the function. A
    reference of all Cg functions is available on:

    http://http.developer.nvidia.com/CgTutorial/cg_tutorial_appendix_e.html

    Depending on the commented lines you can see all cubes in red, blue, or dark
    purple. Try to understand why it is dark purple and not bright purple (Hint:
    Read the section about linear interpolation in 0.py once more).
    */
    //float4 red = float4(1.0, 0.0, 0.0, 1.0);
    //float4 blue = float4(0.0, 0.0, 1.0, 1.0);
    //o_color = lerp(red, blue, 0.0);
    //o_color = lerp(red, blue, 0.5);
    //o_color = lerp(red, blue, 1.0);
}

/*
Only as a final side node, a matrix is maybe not the best solution that humanity
can think of. It is just an idea that has is pros an cons. Maybe you already
heard something about a quaternions. Quaternion helps to solve some problems you
sometime have with matrices if you only use matrices. Matrices in general are an
extremely mighty thing, that are not only helpful in graphic stuff, matrices are
so powerful that they are the fundamental data type of well math tools like
scilab (or matlab for the rich ones of us).

May be it is time to open your browser and try to get some information about
matrices in general and try to do at least one matrix multiplication on
yourself. Try to multiply a 4x4 matrix with another 4x4 matrix by yourself and
try to multiply a 4x4 matrix with a 4x vector. Following link maybe is a good
starting point, although it handles only 3x3 matrices.

http://people.hofstra.edu/Stefan_Waner/realWorld/tutorialsf1/frames3_2.html
*/