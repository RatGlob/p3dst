//Cg

/*
We were using setShaderInput in the Python code. setShaderInput does nothing
more than assign a float4 (there is no possibility to assign a float2 e.g.) to a
shader uniform. Every manually provided input needs a k_ prefix therefore the
panda3drocks shader input has to be written as k_panda3drocks. If you manually
define an uniform in shader, you must at least call setShaderInput on an
appropriate NodePath that uses this shader.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    uniform float4 k_panda3drocks,
    in float4 vtx_position : POSITION,
    out float4 l_my : TEXCOORD0,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
    l_my = k_panda3drocks;
}

/*
This example is a bad idead how to waste a TEXCOORD unit. k_panda3drocks is a
constant assigned to l_my, when l_my it is passed from the vertex shader to
fragment shader it is lineraly interpolated. But a linear interpolated constant,
is a constant. In this sample, it would make more sense if we define our uniform
in the fragment shader than in the vertex shader.
*/
void fshader(
    in float4 l_my : TEXCOORD0,
    out float4 o_color : COLOR)
{
    o_color = l_my;
}

/*
I have to admit here an unknowingness. GLSL does interpolate perspectively
correct (based on the depth buffer the linear interpolation gets a correction),
but I do not know in which circumstances this applies to Cg. It may be possible
that I repeat the word linearly interpolated over and over again although it is
not always exactly true. Both the GLSL manual and the Cg manual only have the
word perspectively correction on one line, there is no explanation. If anyone
has in depth information about this I am happy if you share this knowledge.

Both GLSL and Cg support a keyword noproject to disable this correction. But
Panda3D currently does not support it.

http://www.opengl.org/registry/doc/GLSLangSpec.Full.1.20.8.pdf
http://developer.download.nvidia.com/cg/Cg_2.0/2.0.0015/Cg-2.0_May2008_ReferenceManual.pdf

The OpenGL function glHint has a parameter to enable or disable perspective
correction (GL_PERSPECTIVE_CORRECTION_HINT), but maybe that only applies to
fixed function pipeline. As of OpenGL 2.1 perspective correction should always
be enabled according to the manual.

http://www.opengl.org/sdk/docs/man/xhtml/glHint.xml

I bet that it depends on the GPU vendors daily mood, the moon phase and the
Google result to: "number of horns on a unicorn multiplied by the answer to
life, the universe and everything".
*/

/*
First I like to explain why we need perspective correction. A scan line renderer
like todays GPUs are, transforms all three points of a triangle from 3D to a 2D
screen. After the transformation e.g. the linear interpolation of colors is
calculated. Only if we transform a triangle to our screen we know how much
pixels the triangle will cover. If we like to interpolate in 3D we maybe
interpolate millions of position that are reduced to one pixel if the triangle
is far away, this is obviously infeasible. Open the figures.svg of figures.png
file and look at the figure 5.1. If you look at the first image you can see a
quad that consists of two triangles. You can look at this image from two view
points. First it is possible that is a perspective plane in 3D, second it is a
trapezoid in 2D. Because we talk about linear interpolation in 2D, think of it
as a trapezoid. There are two yellow lines in the image. This lines divide the
trapezoid exactly in the center. Maybe you already see a problem, this is only
true in 2D. In 3D the center of the trapezoid is a bit above the current center.
Further on there are five marked intersections. We need this numbers for the
later images:

1: Exact center for the top line.
2: Exact center for the left line.
3: Exact center for the right line.
4: Exact center for the bottom line.
5: Exact center for the line in the middle.

Now we start with the second image and assign some colors to the vertices. We
now interpolate this values manually at the intersection points:

1: 50% red 50% blue.
2: 100% red 0% blue.
3: 50% red 50% blue.
4: 0% red 100% blue.
5: 50% red 50% blue.

While 1 2 3 and 4 should be easy to calculate maybe 5 is not so obvious. But
because we now that the point is exactly at center between the top right vertex
and the bottom left vertex, the color must be the center between red and blue as
well.

In the third image you can see how this should look like. It looks nice, but it
is not correct, because the average of blue and red (50% red and 50% blue) lies
exactly in the center of the trapezoid and not in the center of the 3D plane we
have. The gradient looks nice because all colors on one horizontal have one and
the same color (point 1, 3 and 5 have the same color e.g.).

In the fourth image we rotate our plane. The only thing that changes are the
vertex colors. The interpolated colors are as follows this time:

1: 0% red 100% blue.
2: 50% red 50% blue.
3: 100% red 0% blue.
4: 50% red 50% blue.
5: 50% red 50% blue.

Point 5 has the same color as in the previous image. Because we have another
gradient now, all vertical lines should have the exact same color, but this is
not true. Point 2, 4 and 5 have the same color, but they are not on the same
line.

In the fifth image you can see the final result. Maybe it is not that obvious
but the green line, tries to show how the 50% line looks like.

The image 2 and 3 show you the problem if you do not apply a perspective
correction. The image 4 and 5 show you the problem if the GPU divides your
quads, into automatically into triangles. If you draw a trapezoid in Blender
e.g. and assign the trapezoid a texture and assign the following UV coordinates
of a grid like texture to the four vertices: (0,0) (1,0) (0,1) (1,1) you can see
the distortion more clearly. But this distortion has nothing to do with
perspective and is only here to show the difference.
*/